{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8514ba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b38212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "NUM_BATCHES = int(1e5)\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 1e-4\n",
    "GENERATE_EVERY  = 100\n",
    "NUM_TOKENS = 16 + 2\n",
    "ENC_SEQ_LEN = 32\n",
    "DEC_SEQ_LEN = 32\n",
    "\n",
    "def cycle():\n",
    "    while True:\n",
    "        prefix = torch.ones((BATCH_SIZE, 1)).long()\n",
    "        src = torch.randint(2, NUM_TOKENS, (BATCH_SIZE, ENC_SEQ_LEN)).long()\n",
    "        tgt = torch.cat((prefix, src), 1)\n",
    "        src_mask = torch.ones(BATCH_SIZE, ENC_SEQ_LEN).bool()\n",
    "        tgt_mask = torch.ones(BATCH_SIZE, tgt.shape[1] - 1).bool()\n",
    "        yield (src, tgt, src_mask, tgt_mask)\n",
    "        \n",
    "def culc_loss(loss_func, inputs, targets):\n",
    "    \"\"\"\n",
    "    損失関数の計算\n",
    "    args:\n",
    "        - loss_func : 損失関数(交差エントロピー)\n",
    "        - input (B x len x d): 入力データ\n",
    "        - target (B x len): ターゲットデータ\n",
    "    \n",
    "    文章ごとに平均をとって、バッチごとに平均をとる\n",
    "    pytorchの交差エントロピー使わない方が収束早いし、lossも小さくなる。。。\n",
    "    どういうことだ？\n",
    "    計算結果が微妙に違う気がするし、nn.CrossEntropyが所望の計算をしてない可能性ある？\n",
    "    \"\"\"\n",
    "    B, l, d = inputs.shape\n",
    "    _loss = 0\n",
    "    loss = 0\n",
    "    for i in range(B):\n",
    "        loss += loss_func(inputs[i], targets[i])# 内部的に文章平均\n",
    "#         _loss += cross_ent(inputs[i], targets[i])\n",
    "#     _loss /= B# バッチ平均\n",
    "    loss /= B\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce9783ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(cycle())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a08d2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src : torch.Size([16, 32])\n",
      "tgt : torch.Size([16, 33])\n",
      "torch.Size([16, 33, 18])\n",
      "3.031921625137329\n",
      "input:   tensor([[ 4, 13, 11, 14, 17,  9, 15,  2,  6,  4, 12, 16,  3,  7, 14, 15, 14, 11,\n",
      "          7, 13,  2, 10,  8, 15,  6,  7,  7,  6,  3,  4,  5, 12]])\n",
      "predicted output:   tensor([[ 7, 10, 12,  3,  2, 12,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "          9,  7,  4, 13,  2, 15,  8,  8,  8,  8,  8,  8,  8,  8]])\n",
      "incorrects: 30\n",
      "src : torch.Size([16, 32])\n",
      "tgt : torch.Size([16, 33])\n",
      "torch.Size([16, 33, 18])\n",
      "2.9528870582580566\n",
      "src : torch.Size([16, 32])\n",
      "tgt : torch.Size([16, 33])\n",
      "torch.Size([16, 33, 18])\n",
      "2.883139133453369\n",
      "src : torch.Size([16, 32])\n",
      "tgt : torch.Size([16, 33])\n",
      "torch.Size([16, 33, 18])\n",
      "2.8683905601501465\n",
      "src : torch.Size([16, 32])\n",
      "tgt : torch.Size([16, 33])\n",
      "torch.Size([16, 33, 18])\n",
      "2.8277370929718018\n",
      "src : torch.Size([16, 32])\n",
      "tgt : torch.Size([16, 33])\n",
      "torch.Size([16, 33, 18])\n",
      "2.820688486099243\n",
      "src : torch.Size([16, 32])\n",
      "tgt : torch.Size([16, 33])\n",
      "torch.Size([16, 33, 18])\n",
      "2.838644027709961\n",
      "src : torch.Size([16, 32])\n",
      "tgt : torch.Size([16, 33])\n",
      "torch.Size([16, 33, 18])\n",
      "2.8622560501098633\n",
      "src : torch.Size([16, 32])\n",
      "tgt : torch.Size([16, 33])\n",
      "torch.Size([16, 33, 18])\n",
      "2.840902328491211\n",
      "src : torch.Size([16, 32])\n",
      "tgt : torch.Size([16, 33])\n",
      "torch.Size([16, 33, 18])\n",
      "2.8312008380889893\n",
      "src : torch.Size([16, 32])\n",
      "tgt : torch.Size([16, 33])\n",
      "torch.Size([16, 33, 18])\n",
      "2.8229877948760986\n",
      "src : torch.Size([16, 32])\n",
      "tgt : torch.Size([16, 33])\n",
      "torch.Size([16, 33, 18])\n",
      "2.852909564971924\n",
      "src : torch.Size([16, 32])\n",
      "tgt : torch.Size([16, 33])\n",
      "torch.Size([16, 33, 18])\n",
      "2.824277639389038\n",
      "src : torch.Size([16, 32])\n",
      "tgt : torch.Size([16, 33])\n",
      "torch.Size([16, 33, 18])\n",
      "2.7924983501434326\n",
      "src : torch.Size([16, 32])\n",
      "tgt : torch.Size([16, 33])\n",
      "torch.Size([16, 33, 18])\n"
     ]
    }
   ],
   "source": [
    "DIMENTION = 512\n",
    "HEAD = 8\n",
    "DEPTH_enc = 1\n",
    "DEPTH_dec = 3\n",
    "\n",
    "transformer = model.Model(\"cpu\", DIMENTION, NUM_TOKENS, 0.0, DEPTH_enc, DEPTH_dec, HEAD, HEAD)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "\n",
    "optim = torch.optim.Adam(transformer.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# training\n",
    "\n",
    "for i in range(NUM_BATCHES):\n",
    "    transformer.train()\n",
    "    src, tgt, src_mask, tgt_mask = next(cycle())\n",
    "    print(\"src : {}\".format(src.shape))\n",
    "    print(\"tgt : {}\".format(tgt.shape))\n",
    "    \n",
    "    out = transformer(src, tgt)\n",
    "    print(out.shape)\n",
    "    loss = culc_loss(criterion, out[:,:-1,:], src)\n",
    "    loss.backward()\n",
    "    print(loss.item())\n",
    "\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "\n",
    "    if i % GENERATE_EVERY == 0:\n",
    "        transformer.eval()\n",
    "        src, _, src_mask, _ = next(cycle())\n",
    "        src, src_mask = src[0:1], src_mask[0:1]\n",
    "        \n",
    "        sample = transformer.generate(src)\n",
    "#         import pdb; pdb.set_trace()\n",
    "#         incorrects = (src != sample).abs().sum()\n",
    "        incorrects = torch.sum(src != sample)\n",
    "\n",
    "        print(f\"input:  \", src)\n",
    "        print(f\"predicted output:  \", sample)\n",
    "        print(f\"incorrects: {incorrects}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a955553b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b47693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e985fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7702973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa4bd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feec4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d6a333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7fc7f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbabaf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b01d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
